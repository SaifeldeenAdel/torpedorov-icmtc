{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8679056,"sourceType":"datasetVersion","datasetId":5202630}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\n\nos.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n\nfrom glob import glob\nimport tensorflow as tf\nimport keras\nfrom keras import layers\n\n\n\"\"\"\n## Define the Transformer Input Layer\n\nWhen processing past target tokens for the decoder, we compute the sum of\nposition embeddings and token embeddings.\n\nWhen processing audio features, we apply convolutional layers to downsample\nthem (via convolution strides) and process local relationships.\n\"\"\"\n\n\nclass TokenEmbedding(layers.Layer):\n    def __init__(self, num_vocab=1000, maxlen=100, num_hid=64):\n        super().__init__()\n        self.emb = keras.layers.Embedding(num_vocab, num_hid)\n        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=num_hid)\n\n    def call(self, x):\n        maxlen = tf.shape(x)[-1]\n        x = self.emb(x)\n        positions = tf.range(start=0, limit=maxlen, delta=1)\n        positions = self.pos_emb(positions)\n        return x + positions\n\n\nclass SpeechFeatureEmbedding(layers.Layer):\n    def __init__(self, num_hid=64, maxlen=100):\n        super().__init__()\n        self.conv1 = keras.layers.Conv1D(\n            num_hid, 11, strides=2, padding=\"same\", activation=\"relu\"\n        )\n        self.conv2 = keras.layers.Conv1D(\n            num_hid, 11, strides=2, padding=\"same\", activation=\"relu\"\n        )\n        self.conv3 = keras.layers.Conv1D(\n            num_hid, 11, strides=2, padding=\"same\", activation=\"relu\"\n        )\n\n    def call(self, x):\n        x = self.conv1(x)\n        x = self.conv2(x)\n        return self.conv3(x)\n\n\n\"\"\"\n## Transformer Encoder Layer\n\"\"\"\n\n\nclass TransformerEncoder(layers.Layer):\n    def __init__(self, embed_dim, num_heads, feed_forward_dim, rate=0.1):\n        super().__init__()\n        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n        self.ffn = keras.Sequential(\n            [\n                layers.Dense(feed_forward_dim, activation=\"relu\"),\n                layers.Dense(embed_dim),\n            ]\n        )\n        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n        self.dropout1 = layers.Dropout(rate)\n        self.dropout2 = layers.Dropout(rate)\n\n    def call(self, inputs, training=False):\n        attn_output = self.att(inputs, inputs)\n        attn_output = self.dropout1(attn_output, training=training)\n        out1 = self.layernorm1(inputs + attn_output)\n        ffn_output = self.ffn(out1)\n        ffn_output = self.dropout2(ffn_output, training=training)\n        return self.layernorm2(out1 + ffn_output)\n\n\n\"\"\"\n## Transformer Decoder Layer\n\"\"\"\n\n\nclass TransformerDecoder(layers.Layer):\n    def __init__(self, embed_dim, num_heads, feed_forward_dim, dropout_rate=0.1):\n        super().__init__()\n        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n        self.layernorm3 = layers.LayerNormalization(epsilon=1e-6)\n        self.self_att = layers.MultiHeadAttention(\n            num_heads=num_heads, key_dim=embed_dim\n        )\n        self.enc_att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n        self.self_dropout = layers.Dropout(0.5)\n        self.enc_dropout = layers.Dropout(0.1)\n        self.ffn_dropout = layers.Dropout(0.1)\n        self.ffn = keras.Sequential(\n            [\n                layers.Dense(feed_forward_dim, activation=\"relu\"),\n                layers.Dense(embed_dim),\n            ]\n        )\n\n    def causal_attention_mask(self, batch_size, n_dest, n_src, dtype):\n        \"\"\"Masks the upper half of the dot product matrix in self attention.\n\n        This prevents flow of information from future tokens to current token.\n        1's in the lower triangle, counting from the lower right corner.\n        \"\"\"\n        i = tf.range(n_dest)[:, None]\n        j = tf.range(n_src)\n        m = i >= j - n_src + n_dest\n        mask = tf.cast(m, dtype)\n        mask = tf.reshape(mask, [1, n_dest, n_src])\n        mult = tf.concat(\n            [tf.expand_dims(batch_size, -1), tf.constant([1, 1], dtype=tf.int32)], 0\n        )\n        return tf.tile(mask, mult)\n\n    def call(self, enc_out, target):\n        input_shape = tf.shape(target)\n#         print(\"input_shape\",input_shape)\n        batch_size = input_shape[0]\n        seq_len = input_shape[1]\n        causal_mask = self.causal_attention_mask(batch_size, seq_len, seq_len, tf.bool)\n        target_att = self.self_att(target, target, attention_mask=causal_mask)\n        target_norm = self.layernorm1(target + self.self_dropout(target_att))\n        enc_out = self.enc_att(target_norm, enc_out)\n        enc_out_norm = self.layernorm2(self.enc_dropout(enc_out) + target_norm)\n        ffn_out = self.ffn(enc_out_norm)\n        ffn_out_norm = self.layernorm3(enc_out_norm + self.ffn_dropout(ffn_out))\n        return ffn_out_norm\n\n\n\"\"\"\n## Complete the Transformer model\n\nOur model takes audio spectrograms as inputs and predicts a sequence of characters.\nDuring training, we give the decoder the target character sequence shifted to the left\nas input. During inference, the decoder uses its own past predictions to predict the\nnext token.\n\"\"\"\n\n\nclass Transformer(keras.Model):\n    def __init__(\n        self,\n        num_hid=64,\n        num_head=2,\n        num_feed_forward=128,\n        source_maxlen=100,\n        target_maxlen=100,\n        num_layers_enc=4,\n        num_layers_dec=1,\n        num_classes=10,\n        **kwargs\n    ):\n        super().__init__(**kwargs)\n        \n        self.num_hid = num_hid\n        self.num_head = num_head\n        self.num_feed_forward = num_feed_forward\n        self.source_maxlen = source_maxlen\n        self.target_maxlen = target_maxlen\n        self.num_layers_enc = num_layers_enc\n        self.num_layers_dec = num_layers_dec\n        self.num_classes = num_classes\n        self.loss_metric = keras.metrics.Mean(name=\"loss\")\n        self.num_layers_enc = num_layers_enc\n        self.num_layers_dec = num_layers_dec\n        self.target_maxlen = target_maxlen\n        self.num_classes = num_classes\n\n        self.enc_input = SpeechFeatureEmbedding(num_hid=num_hid, maxlen=source_maxlen)\n        self.dec_input = TokenEmbedding(\n            num_vocab=num_classes, maxlen=target_maxlen, num_hid=num_hid\n        )\n\n        self.encoder = keras.Sequential(\n            [self.enc_input]\n            + [\n                TransformerEncoder(num_hid, num_head, num_feed_forward)\n                for _ in range(num_layers_enc)\n            ]\n        )\n\n        for i in range(num_layers_dec):\n            setattr(\n                self,\n                f\"dec_layer_{i}\",\n                TransformerDecoder(num_hid, num_head, num_feed_forward),\n            )\n\n        self.classifier = layers.Dense(num_classes)\n\n    def decode(self, enc_out, target):\n        y = self.dec_input(target)\n        for i in range(self.num_layers_dec):\n            y = getattr(self, f\"dec_layer_{i}\")(enc_out, y)\n        return y\n\n    def call(self, inputs):\n        source = inputs[0]\n        target = inputs[1]\n        x = self.encoder(source)\n        y = self.decode(x, target)\n        return self.classifier(y)\n    \n    def get_config(self):\n        config = super().get_config()\n        config.update({\n            \"num_hid\": self.num_hid,\n            \"num_head\": self.num_head,\n            \"num_feed_forward\": self.num_feed_forward,\n            \"source_maxlen\": self.source_maxlen,\n            \"target_maxlen\": self.target_maxlen,\n            \"num_layers_enc\": self.num_layers_enc,\n            \"num_layers_dec\": self.num_layers_dec,\n            \"num_classes\": self.num_classes,\n        })\n        return config\n\n    @property\n    def metrics(self):\n        return [self.loss_metric]\n\n    def train_step(self, batch):\n        \"\"\"Processes one batch inside model.fit().\"\"\"\n        source = batch[\"source\"]\n        target = batch[\"target\"]\n        dec_input = target[:, :-1]\n        dec_target = target[:, 1:]\n        with tf.GradientTape() as tape:\n            preds = self([source, dec_input])\n            one_hot = tf.one_hot(dec_target, depth=self.num_classes)\n            mask = tf.math.logical_not(tf.math.equal(dec_target, 0))\n            loss = model.compute_loss(None, one_hot, preds, sample_weight=mask)\n        trainable_vars = self.trainable_variables\n        gradients = tape.gradient(loss, trainable_vars)\n        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n        self.loss_metric.update_state(loss)\n        return {\"loss\": self.loss_metric.result()}\n\n    def test_step(self, batch):\n        source = batch[\"source\"]\n        target = batch[\"target\"]\n        dec_input = target[:, :-1]\n        dec_target = target[:, 1:]\n        preds = self([source, dec_input])\n        one_hot = tf.one_hot(dec_target, depth=self.num_classes)\n        mask = tf.math.logical_not(tf.math.equal(dec_target, 0))\n        loss = model.compute_loss(None, one_hot, preds, sample_weight=mask)\n        self.loss_metric.update_state(loss)\n        return {\"loss\": self.loss_metric.result()}\n\n    def generate(self, source, target_start_token_idx):\n        \"\"\"Performs inference over one batch of inputs using greedy decoding.\"\"\"\n        bs = tf.shape(source)[0]\n        enc = self.encoder(source)\n        dec_input = tf.ones((bs, 1), dtype=tf.int32) * target_start_token_idx\n        dec_logits = []\n        for i in range(self.target_maxlen - 1):\n            dec_out = self.decode(enc, dec_input)\n            logits = self.classifier(dec_out)\n            logits = tf.argmax(logits, axis=-1, output_type=tf.int32)\n            last_logit = tf.expand_dims(logits[:, -1], axis=-1)\n            dec_logits.append(last_logit)\n            dec_input = tf.concat([dec_input, last_logit], axis=-1)\n        return dec_input\n\n\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-01T04:29:04.383485Z","iopub.execute_input":"2024-07-01T04:29:04.383840Z","iopub.status.idle":"2024-07-01T04:29:16.220650Z","shell.execute_reply.started":"2024-07-01T04:29:04.383784Z","shell.execute_reply":"2024-07-01T04:29:16.219840Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"2024-07-01 04:29:06.091940: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-07-01 04:29:06.092049: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-07-01 04:29:06.209693: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"import os \nfrom glob import glob\nfrom numpy import vectorize \nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers \nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport torch\n\n\n\n\nimport os\nimport pandas as pd\n\ndef get_data(csv_path1, csv_path2, lim1=32000, lim2=2500):\n    \"\"\"\n    Reads two CSV files, preprocesses data, and extracts audio and transcript information.\n\n    Args:\n      csv_path1: Path to the first CSV file containing audio and text data.\n      csv_path2: Path to the second CSV file containing audio and text data.\n      lim1: Limit on the number of rows to read from the first CSV file (default: 50000).\n      lim2: Limit on the number of rows to read from the second CSV file (default: 2500).\n\n    Returns:\n      A list of dictionaries containing \"audio\" and \"text\" keys.\n    \"\"\"\n    # Read and process the first CSV\n    df1 = pd.read_csv(csv_path1, encoding='utf-8')\n    df1 = df1.head(lim1)  # Read only the first 'lim1' rows\n    df1 = df1[df1['audio'].notna() & df1['transcript'].notna()]\n    df1 = df1[~df1['transcript'].str.contains(r'\\s<\\s|\\[|÷|=', na=False)]\n    df1 = df1.rename(columns={\"audio\": \"ID\"})\n    df1['file_path'] = df1['ID'].apply(lambda x: os.path.join(train_files_path, x + \".wav\"))\n\n    # Read and process the second CSV\n    df2 = pd.read_csv(csv_path2, encoding='utf-8')\n    df2 = df2.head(lim2)  # Read only the first 'lim2' rows\n    df2 = df2[df2['audio'].notna() & df2['transcript'].notna()]\n    df2 = df2[~df2['transcript'].str.contains(r'\\s<\\s|\\[|÷|=', na=False)]\n    df2 = df2.rename(columns={\"audio\": \"ID\"})\n    df2['file_path'] = df2['ID'].apply(lambda x: os.path.join(adapt_files_path, x + \".wav\"))\n\n    # Concatenate the DataFrames\n    df = pd.concat([df1, df2], ignore_index=True)\n    df = df.sample(frac=1).reset_index(drop=True)\n\n    # Create the final data list\n    data = df[[\"file_path\", \"transcript\"]].to_dict(orient='records')\n    data = [{'audio': item['file_path'], 'text': item['transcript']} for item in data]\n\n    return data\n\n\n\"\"\"\n## Preprocess the dataset\n\"\"\"\n\n\nclass VectorizeChar:\n    def __init__(self, max_len=50):\n        self.vocab = (\n                        [\"-\", \"#\", \"<\", \">\"]\n                        + ['آ', 'إ', 'ا', 'ب', 'ت', 'ث', 'ج', 'ح', 'خ', 'د', 'ذ'\n                            , 'ر', 'ز', 'س', 'ش', 'ص', 'ض', 'ط', 'ظ', 'ع', 'غ',\n                             'ف', 'ق', 'ك', 'ل', 'م', 'ن', 'ه', 'و', 'ي', 'أ', 'ؤ'\n                             , 'ئ', 'ة', 'ى', 'ء', ' ', 'f','o','l', \"،\", \"ٱ\",\"ڨ\", \"چ\"]\n                        + [\" \", \".\", \",\", \"?\"]\n        )\n        self.max_len = max_len\n        self.char_to_idx = {}\n        for i, ch in enumerate(self.vocab):\n            self.char_to_idx[ch] = i\n\n    def __call__(self, text):\n        text = text.lower()\n        text = text[: self.max_len - 2]\n        text = \"<\" + text + \">\"\n        pad_len = self.max_len - len(text)\n        return [self.char_to_idx.get(ch, 1) for ch in text] + [0] * pad_len\n\n    def get_vocabulary(self):\n        return self.vocab\n\ntrain_csv = \"/kaggle/input/mtc-asr/train.csv\"\nadapt_csv = \"/kaggle/input/mtc-asr/adapt.csv\"\n\ntrain_files_path = \"/kaggle/input/mtc-asr/train\"\nadapt_files_path = \"/kaggle/input/mtc-asr/adapt\"\noutput_path = \"/kaggle/working\"\n\nmax_target_len = 200  # all transcripts in out data are < 200 characters\ndata = get_data(train_csv, adapt_csv)\nvectorizer = VectorizeChar(max_target_len)\nprint(\"vocab size\", len(vectorizer.get_vocabulary()))\n\n\ndef create_text_ds(data):\n    texts = [_[\"text\"] for _ in data]\n    text_ds = [vectorizer(t) for t in texts]\n    text_ds = tf.data.Dataset.from_tensor_slices(text_ds)\n    return text_ds\n\ndef create_id_ds(data):\n    texts = [_[\"audio\"] for _ in data]\n    text_ds = [vectorizer(t) for t in texts]\n    text_ds = tf.data.Dataset.from_tensor_slices(text_ds)\n    return text_ds\n\n\ndef path_to_audio(path):\n    # spectrogram using stft\n    audio = tf.io.read_file(path)\n    audio, _ = tf.audio.decode_wav(audio, 1)\n    audio = tf.squeeze(audio, axis=-1)\n    stfts = tf.signal.stft(audio, frame_length=200, frame_step=80, fft_length=256)\n    x = tf.math.pow(tf.abs(stfts), 0.5)\n    mx=tf.math.reduce_max(x)\n    # normalisation\n    means = tf.math.reduce_mean(x, 1, keepdims=True)\n    stddevs = tf.math.reduce_std(x, 1, keepdims=True)\n    epsilon = 1e-7  # Very small number\n    stddevs = tf.where(stddevs == 0, epsilon, stddevs)  # Replace zero stddevs with epsilon\n    \n    x = (x - means) / stddevs\n\n    audio_len = tf.shape(x)[0]\n    # padding to 10 seconds\n    pad_len = int(2754*1.5)\n    paddings = tf.constant([[0, pad_len], [0, 0]])\n    x = tf.pad(x, paddings, \"CONSTANT\")[:pad_len, :]\n    return x\n\n\ndef create_audio_ds(data):\n    flist = [_[\"audio\"] for _ in data]\n    audio_ds = tf.data.Dataset.from_tensor_slices(flist)\n    audio_ds = audio_ds.map(path_to_audio, num_parallel_calls=tf.data.AUTOTUNE)\n    return audio_ds\n\n\ndef create_tf_dataset(data, bs=4):\n    audio_ds = create_audio_ds(data)\n    text_ds = create_text_ds(data)\n    ds = tf.data.Dataset.zip((audio_ds, text_ds))\n    ds = ds.map(lambda x, y: {\"source\": x, \"target\": y})\n    ds = ds.batch(bs)\n    ds = ds.prefetch(tf.data.AUTOTUNE)\n    return ds\n\n\nsplit = int(len(data) * 0.99)\ntrain_data = data[:split]\ntest_data = data[split-20:split]\n\nds = create_tf_dataset(train_data, bs=64)\n\nval_ds = create_tf_dataset(test_data, bs=4)\n\n\"\"\"\n### Callbacks to display predictions\n\"\"\"\n\n","metadata":{"execution":{"iopub.status.busy":"2024-07-01T04:59:57.068894Z","iopub.execute_input":"2024-07-01T04:59:57.069371Z","iopub.status.idle":"2024-07-01T05:00:20.690625Z","shell.execute_reply.started":"2024-07-01T04:59:57.069328Z","shell.execute_reply":"2024-07-01T05:00:20.689753Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"vocab size 52\n","output_type":"stream"},{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"'\\n### Callbacks to display predictions\\n'"},"metadata":{}}]},{"cell_type":"code","source":"\nclass DisplayOutputs(keras.callbacks.Callback):\n    def __init__(\n        self, batch, idx_to_token, target_start_token_idx=27, target_end_token_idx=28\n    ):\n        \"\"\"Displays a batch of outputs after every epoch\n\n        Args:\n            batch: A test batch containing the keys \"source\" and \"target\"\n            idx_to_token: A List containing the vocabulary tokens corresponding to their indices\n            target_start_token_idx: A start token index in the target vocabulary\n            target_end_token_idx: An end token index in the target vocabulary\n        \"\"\"\n        self.batch = batch\n        self.target_start_token_idx = target_start_token_idx\n        self.target_end_token_idx = target_end_token_idx\n        self.idx_to_char = idx_to_token\n\n    def on_epoch_end(self, epoch, logs=None):\n        if epoch % 5 != 0:\n            return\n        source = self.batch[\"source\"]\n        target = self.batch[\"target\"].numpy()\n        bs = tf.shape(source)[0]\n        preds = self.model.generate(source, self.target_start_token_idx)\n        preds = preds.numpy()\n        target_words=[]\n        pred=[]\n        for i in range(bs-1,bs):\n            target_text = \"\".join([self.idx_to_char[_] for _ in target[i, :]])\n            prediction = \"\"\n            for idx in preds[i, :]:\n                prediction += self.idx_to_char[idx]\n                if idx == self.target_end_token_idx:\n                    break\n            target_words+=[target_text.replace('-','')]\n            pred+=[prediction]\n        for i in range(1):\n            print(f\"target:     {target_words[i]}\")\n            print(f\"prediction: {pred[i]}\\n\")\n\n    def on_test_batch_end(self, batch, logs=None):\n        source = self.batch[\"source\"]\n        target = self.batch[\"target\"].numpy()\n        bs = tf.shape(source)[0]\n        preds = self.model.generate(source, self.target_start_token_idx)\n        preds = preds.numpy()\n        \n            \n\n\"\"\"\n## Learning rate schedule\n\"\"\"\n\n\nclass CustomSchedule(keras.optimizers.schedules.LearningRateSchedule):\n    def __init__(\n        self,\n        init_lr=0.00001,\n        lr_after_warmup=0.001,\n        final_lr=0.00001,\n        warmup_epochs=15,\n        decay_epochs=85,\n        steps_per_epoch=203,\n    ):\n        super().__init__()\n        self.init_lr = init_lr\n        self.lr_after_warmup = lr_after_warmup\n        self.final_lr = final_lr\n        self.warmup_epochs = warmup_epochs\n        self.decay_epochs = decay_epochs\n        self.steps_per_epoch = steps_per_epoch\n\n    def calculate_lr(self, epoch):\n        \"\"\"linear warm up - linear decay\"\"\"\n        warmup_lr = (\n            self.init_lr\n            + ((self.lr_after_warmup - self.init_lr) / (self.warmup_epochs - 1)) * epoch\n        )\n        decay_lr = tf.math.maximum(\n            self.final_lr,\n            self.lr_after_warmup\n            - (epoch - self.warmup_epochs)\n            * (self.lr_after_warmup - self.final_lr)\n            / self.decay_epochs,\n        )\n        return tf.math.minimum(warmup_lr, decay_lr)\n\n    def __call__(self, step):\n        epoch = step // self.steps_per_epoch\n        epoch = tf.cast(epoch, \"float32\")\n        return self.calculate_lr(epoch)\n    \n    def get_config(self):\n        config = {\n            \"init_lr\": self.init_lr,\n            \"lr_after_warmup\": self.lr_after_warmup,\n            \"final_lr\": self.final_lr,\n            \"warmup_epochs\": self.warmup_epochs,\n            \"decay_epochs\": self.decay_epochs,\n            \"steps_per_epoch\": self.steps_per_epoch,\n        }\n        return config\n","metadata":{"execution":{"iopub.status.busy":"2024-07-01T04:34:42.665502Z","iopub.execute_input":"2024-07-01T04:34:42.665866Z","iopub.status.idle":"2024-07-01T04:34:42.683138Z","shell.execute_reply.started":"2024-07-01T04:34:42.665834Z","shell.execute_reply":"2024-07-01T04:34:42.682192Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# import shutil\n# shutil.rmtree(\"/kaggle/working/ASAR-v2/backup/\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"newpath = r'/kaggle/working/ASAR-v2/backup' \nif not os.path.exists(newpath):\n    os.makedirs(newpath)","metadata":{"execution":{"iopub.status.busy":"2024-06-30T16:33:33.025037Z","iopub.execute_input":"2024-06-30T16:33:33.025428Z","iopub.status.idle":"2024-06-30T16:33:33.030632Z","shell.execute_reply.started":"2024-06-30T16:33:33.025397Z","shell.execute_reply":"2024-06-30T16:33:33.029641Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"backup_dir= r'/kaggle/working/ASAR-v2/backup'\ntrain_checkpoint = keras.callbacks.BackupAndRestore(\n    backup_dir, save_freq=\"epoch\", delete_checkpoint=False\n)","metadata":{"execution":{"iopub.status.busy":"2024-06-30T16:18:07.762147Z","iopub.execute_input":"2024-06-30T16:18:07.762587Z","iopub.status.idle":"2024-06-30T16:18:07.768024Z","shell.execute_reply.started":"2024-06-30T16:18:07.762555Z","shell.execute_reply":"2024-06-30T16:18:07.767051Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"\n\"\"\"\n## Create & train the end-to-end model\n\"\"\"\n\nbatch = next(iter(val_ds))\n\n# The vocabulary to convert predicted indices into characters\nidx_to_char = vectorizer.get_vocabulary()\ndisplay_cb = DisplayOutputs(\n    batch, idx_to_char, target_start_token_idx=2, target_end_token_idx=3\n)  # set the arguments as per vocabulary index for '<' and '>'\n","metadata":{"execution":{"iopub.status.busy":"2024-07-01T04:35:08.091682Z","iopub.execute_input":"2024-07-01T04:35:08.092329Z","iopub.status.idle":"2024-07-01T04:35:08.216647Z","shell.execute_reply.started":"2024-07-01T04:35:08.092296Z","shell.execute_reply":"2024-07-01T04:35:08.215817Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"newpath = r'/kaggle/working/ASAR-v3/' \nif not os.path.exists(newpath):\n    os.makedirs(newpath)\nfilepath=\"/kaggle/working/ASAR-v3/weights-improvement-{epoch:02d}.model.keras\"\ncheckpoint = keras.callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto')\n","metadata":{"execution":{"iopub.status.busy":"2024-07-01T04:35:26.374007Z","iopub.execute_input":"2024-07-01T04:35:26.374898Z","iopub.status.idle":"2024-07-01T04:35:26.380005Z","shell.execute_reply.started":"2024-07-01T04:35:26.374865Z","shell.execute_reply":"2024-07-01T04:35:26.378965Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"\n# backup_dir= r'/kaggle/working/ASAR-v2/backup'\n\n# checkpoint = keras.callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto')\n\n# train_checkpoint = keras.callbacks.BackupAndRestore(\n#     backup_dir, save_freq=\"epoch\", delete_checkpoint=False\n# )\n\n# \"\"\"\n# ## Create & train the end-to-end model\n# \"\"\"\n\n# batch = next(iter(val_ds))\n\n# # The vocabulary to convert predicted indices into characters\n# idx_to_char = vectorizer.get_vocabulary()\n# display_cb = DisplayOutputs(\n#     batch, idx_to_char, target_start_token_idx=2, target_end_token_idx=3\n# )  # set the arguments as per vocabulary index for '<' and '>'\n\n\n\n# model = Transformer(\n#     num_hid=200,\n#     num_head=2,\n#     num_feed_forward=400,\n#     target_maxlen=max_target_len,\n#     num_layers_enc=4,\n#     num_layers_dec=1,\n#     num_classes=52,\n# )\n# loss_fn = keras.losses.CategoricalCrossentropy(\n#     from_logits=True,\n#     label_smoothing=0.1,\n# )\n\n# learning_rate = CustomSchedule(\n#     init_lr=0.00001,\n#     lr_after_warmup=0.001,\n#     final_lr=0.00001,\n#     warmup_epochs=15,\n#     decay_epochs=85,\n#     steps_per_epoch=len(ds),\n# )\n# optimizer = keras.optimizers.Adam(learning_rate)\n\n# # load_epoch=2\n# # if os.path.exists(filepath.format(epoch=load_epoch)):\n# #     model.load_model(filepath.format(epoch=load_epoch))\n# #     print(\"Checkpoint loaded.\")\n# checkpoint_path=\"/kaggle/working/ASAR-v2/backup/latest.weights.h5\"\n# # model.load_weights(checkpoint_path)\n\n# model.compile(optimizer=optimizer, loss=loss_fn)\n# history = model.fit(ds, validation_data=val_ds, callbacks=[display_cb],epochs=1)\n\n# history = model.fit(ds, validation_data=val_ds, callbacks=[checkpoint,train_checkpoint,display_cb],epochs=100)\n\n# model.save('my_model_v3.keras')\n\n# \"\"\"\n# In practice, you should train for around 100 epochs or more.\n\n# Some of the predicted text at or around epoch 35 may look as follows:\n\n# target:     <as they sat in the car, frazier asked oswald where his lunch was>\n# prediction: <as they sat in the car frazier his lunch ware mis lunch was>\n\n# target:     <under the entry for may one, nineteen sixty,>\n# prediction: <under the introus for may monee, nin the sixty,>\n\n# \"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-07-01T05:00:23.668078Z","iopub.execute_input":"2024-07-01T05:00:23.668897Z","iopub.status.idle":"2024-07-01T11:17:35.982497Z","shell.execute_reply.started":"2024-07-01T05:00:23.668864Z","shell.execute_reply":"2024-07-01T11:17:35.981507Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stderr","text":"W0000 00:00:1719810048.423230     101 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 354ms/step - loss: 1.2121","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1719810252.273900     101 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n/opt/conda/lib/python3.10/site-packages/keras/src/ops/nn.py:545: UserWarning: You are using a softmax over axis 3 of a tensor of shape (4, 2, 1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"target:     <دفع ضريبة الحريه الدم الدم واسترداد الأرض والعزه والكرامه ليس لها خيار اخر>\nprediction: <و ال ال ال ال ال الال ال الي الي ال ال الي ال الي ال الي الالي ال ا الا الي ا الي ال الي الالي ال بي الي ال مالي م الي الي م ال اللم ال ا ال ا ا ال الم الي الي م الي ا و ا الي الماللي ال ا عل المالي \n\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m268s\u001b[0m 422ms/step - loss: 1.2119 - val_loss: 0.9292\nEpoch 1/100\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332ms/step - loss: 0.9978\nEpoch 1: saving model to /kaggle/working/ASAR-v3/weights-improvement-01.model.keras\ntarget:     <دفع ضريبة الحريه الدم الدم واسترداد الأرض والعزه والكرامه ليس لها خيار اخر>\nprediction: <و اللالالي الل الي الي الي الي اللي اللي الي الي الي الي الي اللي الي الي الي الي الي الي الي الليه اليه الي الي الي الي الي اليه اللمالي الللليه مالولي مالي اللي الي الي المالللماللي اللال الالمالي>\n\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m229s\u001b[0m 397ms/step - loss: 0.9978 - val_loss: 0.8864\nEpoch 2/100\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332ms/step - loss: 0.9732\nEpoch 2: saving model to /kaggle/working/ASAR-v3/weights-improvement-02.model.keras\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 387ms/step - loss: 0.9732 - val_loss: 0.8750\nEpoch 3/100\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332ms/step - loss: 0.9618\nEpoch 3: saving model to /kaggle/working/ASAR-v3/weights-improvement-03.model.keras\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 386ms/step - loss: 0.9618 - val_loss: 0.8517\nEpoch 4/100\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 333ms/step - loss: 0.9289\nEpoch 4: saving model to /kaggle/working/ASAR-v3/weights-improvement-04.model.keras\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 387ms/step - loss: 0.9288 - val_loss: 0.7678\nEpoch 5/100\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 331ms/step - loss: 0.8486\nEpoch 5: saving model to /kaggle/working/ASAR-v3/weights-improvement-05.model.keras\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 386ms/step - loss: 0.8486 - val_loss: 0.6956\nEpoch 6/100\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 331ms/step - loss: 0.7937\nEpoch 6: saving model to /kaggle/working/ASAR-v3/weights-improvement-06.model.keras\ntarget:     <دفع ضريبة الحريه الدم الدم واسترداد الأرض والعزه والكرامه ليس لها خيار اخر>\nprediction: <دفع الوقار الأرب الأربع و الأرب الأربع وال الأربع والاز الأرب الأربع وال الأرالي الي الي الي الي الي الي الي اليه>\n\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 396ms/step - loss: 0.7936 - val_loss: 0.6418\nEpoch 7/100\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332ms/step - loss: 0.7512\nEpoch 7: saving model to /kaggle/working/ASAR-v3/weights-improvement-07.model.keras\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 387ms/step - loss: 0.7512 - val_loss: 0.5918\nEpoch 8/100\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 333ms/step - loss: 0.7192\nEpoch 8: saving model to /kaggle/working/ASAR-v3/weights-improvement-08.model.keras\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 387ms/step - loss: 0.7192 - val_loss: 0.5503\nEpoch 9/100\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 333ms/step - loss: 0.6950\nEpoch 9: saving model to /kaggle/working/ASAR-v3/weights-improvement-09.model.keras\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 387ms/step - loss: 0.6950 - val_loss: 0.5187\nEpoch 10/100\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 333ms/step - loss: 0.6776\nEpoch 10: saving model to /kaggle/working/ASAR-v3/weights-improvement-10.model.keras\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 387ms/step - loss: 0.6776 - val_loss: 0.4873\nEpoch 11/100\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 333ms/step - loss: 0.6626\nEpoch 11: saving model to /kaggle/working/ASAR-v3/weights-improvement-11.model.keras\ntarget:     <دفع ضريبة الحريه الدم الدم واسترداد الأرض والعزه والكرامه ليس لها خيار اخر>\nprediction: <دفع والعيز والكرام واستدم واستدم الأرض والكرام واستدم والكرامه والكرامه والكرام ال ال ال ال الأر>\n\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m229s\u001b[0m 397ms/step - loss: 0.6626 - val_loss: 0.4693\nEpoch 12/100\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 333ms/step - loss: 0.6511\nEpoch 12: saving model to /kaggle/working/ASAR-v3/weights-improvement-12.model.keras\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 387ms/step - loss: 0.6510 - val_loss: 0.4561\nEpoch 13/100\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 333ms/step - loss: 0.6403\nEpoch 13: saving model to /kaggle/working/ASAR-v3/weights-improvement-13.model.keras\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 387ms/step - loss: 0.6403 - val_loss: 0.4448\nEpoch 14/100\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 333ms/step - loss: 0.6321\nEpoch 14: saving model to /kaggle/working/ASAR-v3/weights-improvement-14.model.keras\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 386ms/step - loss: 0.6321 - val_loss: 0.4356\nEpoch 15/100\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 333ms/step - loss: 0.6183\nEpoch 15: saving model to /kaggle/working/ASAR-v3/weights-improvement-15.model.keras\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 386ms/step - loss: 0.6183 - val_loss: 0.4277\nEpoch 16/100\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 333ms/step - loss: 0.5970\nEpoch 16: saving model to /kaggle/working/ASAR-v3/weights-improvement-16.model.keras\ntarget:     <دفع ضريبة الحريه الدم الدم واسترداد الأرض والعزه والكرامه ليس لها خيار اخر>\nprediction: <دفع الدم والعزه والعزه والعز والعزه والعز والعزه والعزه والعزه والعزه والعيز والكرامه>\n\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m229s\u001b[0m 397ms/step - loss: 0.5970 - val_loss: 0.4211\nEpoch 17/100\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 333ms/step - loss: 0.5865\nEpoch 17: saving model to /kaggle/working/ASAR-v3/weights-improvement-17.model.keras\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 387ms/step - loss: 0.5865 - val_loss: 0.4025\nEpoch 18/100\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332ms/step - loss: 0.5759\nEpoch 18: saving model to /kaggle/working/ASAR-v3/weights-improvement-18.model.keras\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 386ms/step - loss: 0.5759 - val_loss: 0.3877\nEpoch 19/100\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 333ms/step - loss: 0.5705\nEpoch 19: saving model to /kaggle/working/ASAR-v3/weights-improvement-19.model.keras\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 386ms/step - loss: 0.5705 - val_loss: 0.4019\nEpoch 20/100\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332ms/step - loss: 0.5583\nEpoch 20: saving model to /kaggle/working/ASAR-v3/weights-improvement-20.model.keras\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 386ms/step - loss: 0.5582 - val_loss: 0.3792\nEpoch 21/100\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332ms/step - loss: 0.5440\nEpoch 21: saving model to /kaggle/working/ASAR-v3/weights-improvement-21.model.keras\ntarget:     <دفع ضريبة الحريه الدم الدم واسترداد الأرض والعزه والكرامه ليس لها خيار اخر>\nprediction: <دفع دم والعزه والعزه والعزه والعزه والعزه والعزه والعزه والعزه والعزه والعزه والعزه و العيز و ولازوريه الأرض>\n\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 396ms/step - loss: 0.5440 - val_loss: 0.3882\nEpoch 22/100\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 333ms/step - loss: 0.5413\nEpoch 22: saving model to /kaggle/working/ASAR-v3/weights-improvement-22.model.keras\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 386ms/step - loss: 0.5413 - val_loss: 0.3635\nEpoch 23/100\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 333ms/step - loss: 0.5267\nEpoch 23: saving model to /kaggle/working/ASAR-v3/weights-improvement-23.model.keras\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 386ms/step - loss: 0.5267 - val_loss: 0.3531\nEpoch 24/100\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 333ms/step - loss: 0.5198\nEpoch 24: saving model to /kaggle/working/ASAR-v3/weights-improvement-24.model.keras\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 386ms/step - loss: 0.5198 - val_loss: 0.3466\nEpoch 25/100\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 333ms/step - loss: 0.5400\nEpoch 25: saving model to /kaggle/working/ASAR-v3/weights-improvement-25.model.keras\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 386ms/step - loss: 0.5401 - val_loss: 0.4571\nEpoch 26/100\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332ms/step - loss: 0.5634\nEpoch 26: saving model to /kaggle/working/ASAR-v3/weights-improvement-26.model.keras\ntarget:     <دفع ضريبة الحريه الدم الدم واسترداد الأرض والعزه والكرامه ليس لها خيار اخر>\nprediction: <دفع ده في حدار ليه ليس لا خيار والعزه و الكرامه ليس لأ دم ليس لأ>\n\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m229s\u001b[0m 396ms/step - loss: 0.5634 - val_loss: 0.4024\nEpoch 27/100\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 333ms/step - loss: 0.5311\nEpoch 27: saving model to /kaggle/working/ASAR-v3/weights-improvement-27.model.keras\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 386ms/step - loss: 0.5311 - val_loss: 0.3741\nEpoch 28/100\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332ms/step - loss: 0.5123\nEpoch 28: saving model to /kaggle/working/ASAR-v3/weights-improvement-28.model.keras\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 385ms/step - loss: 0.5123 - val_loss: 0.3543\nEpoch 29/100\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332ms/step - loss: 0.5023\nEpoch 29: saving model to /kaggle/working/ASAR-v3/weights-improvement-29.model.keras\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 387ms/step - loss: 0.5023 - val_loss: 0.3447\nEpoch 30/100\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332ms/step - loss: 0.4942\nEpoch 30: saving model to /kaggle/working/ASAR-v3/weights-improvement-30.model.keras\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 386ms/step - loss: 0.4942 - val_loss: 0.3366\nEpoch 31/100\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 333ms/step - loss: 0.4891\nEpoch 31: saving model to /kaggle/working/ASAR-v3/weights-improvement-31.model.keras\ntarget:     <دفع ضريبة الحريه الدم الدم واسترداد الأرض والعزه والكرامه ليس لها خيار اخر>\nprediction: <دفع دم والعزه والكرامه ليس له خيار والعزه والكرامه ليس لا خيار ليس لها خيار ليس لها خياره على الدم>\n\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m229s\u001b[0m 397ms/step - loss: 0.4891 - val_loss: 0.3314\nEpoch 32/100\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332ms/step - loss: 0.4823\nEpoch 32: saving model to /kaggle/working/ASAR-v3/weights-improvement-32.model.keras\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 386ms/step - loss: 0.4823 - val_loss: 0.3234\nEpoch 33/100\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332ms/step - loss: 0.4751\nEpoch 33: saving model to /kaggle/working/ASAR-v3/weights-improvement-33.model.keras\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 386ms/step - loss: 0.4751 - val_loss: 0.3170\nEpoch 34/100\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 333ms/step - loss: 0.4698\nEpoch 34: saving model to /kaggle/working/ASAR-v3/weights-improvement-34.model.keras\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 386ms/step - loss: 0.4698 - val_loss: 0.3154\nEpoch 35/100\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 333ms/step - loss: 0.4682\nEpoch 35: saving model to /kaggle/working/ASAR-v3/weights-improvement-35.model.keras\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 386ms/step - loss: 0.4682 - val_loss: 0.3140\nEpoch 36/100\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332ms/step - loss: 0.4659\nEpoch 36: saving model to /kaggle/working/ASAR-v3/weights-improvement-36.model.keras\ntarget:     <دفع ضريبة الحريه الدم الدم واسترداد الأرض والعزه والكرامه ليس لها خيار اخر>\nprediction: <دفع دم ليس سلعه خيار اخر والعزه والكرامه ليس سلعه خيار اخر والعزه والكرامه ليس سلها خيار>\n\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m229s\u001b[0m 397ms/step - loss: 0.4659 - val_loss: 0.3135\nEpoch 37/100\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332ms/step - loss: 0.4627\nEpoch 37: saving model to /kaggle/working/ASAR-v3/weights-improvement-37.model.keras\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 385ms/step - loss: 0.4627 - val_loss: 0.3123\nEpoch 38/100\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332ms/step - loss: 0.4591\nEpoch 38: saving model to /kaggle/working/ASAR-v3/weights-improvement-38.model.keras\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 385ms/step - loss: 0.4591 - val_loss: 0.3060\nEpoch 39/100\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332ms/step - loss: 0.4554\nEpoch 39: saving model to /kaggle/working/ASAR-v3/weights-improvement-39.model.keras\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 385ms/step - loss: 0.4554 - val_loss: 0.2995\nEpoch 40/100\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332ms/step - loss: 0.4582\nEpoch 40: saving model to /kaggle/working/ASAR-v3/weights-improvement-40.model.keras\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 385ms/step - loss: 0.4582 - val_loss: 0.3128\nEpoch 41/100\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332ms/step - loss: 0.4624\nEpoch 41: saving model to /kaggle/working/ASAR-v3/weights-improvement-41.model.keras\ntarget:     <دفع ضريبة الحريه الدم الدم واسترداد الأرض والعزه والكرامه ليس لها خيار اخر>\nprediction: <دفع ضريبة الحريه الدم واسترداد الأرض والعزه والكرامه ليس لها خيار اخر>\n\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 396ms/step - loss: 0.4624 - val_loss: 0.2951\nEpoch 42/100\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332ms/step - loss: 0.4478\nEpoch 42: saving model to /kaggle/working/ASAR-v3/weights-improvement-42.model.keras\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 386ms/step - loss: 0.4478 - val_loss: 0.2891\nEpoch 43/100\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332ms/step - loss: 0.4388\nEpoch 43: saving model to /kaggle/working/ASAR-v3/weights-improvement-43.model.keras\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 385ms/step - loss: 0.4388 - val_loss: 0.2854\nEpoch 44/100\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 331ms/step - loss: 0.4340\nEpoch 44: saving model to /kaggle/working/ASAR-v3/weights-improvement-44.model.keras\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 385ms/step - loss: 0.4340 - val_loss: 0.2823\nEpoch 45/100\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332ms/step - loss: 0.4311\nEpoch 45: saving model to /kaggle/working/ASAR-v3/weights-improvement-45.model.keras\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 386ms/step - loss: 0.4311 - val_loss: 0.2830\nEpoch 46/100\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332ms/step - loss: 0.4347\nEpoch 46: saving model to /kaggle/working/ASAR-v3/weights-improvement-46.model.keras\ntarget:     <دفع ضريبة الحريه الدم الدم واسترداد الأرض والعزه والكرامه ليس لها خيار اخر>\nprediction: <دفع الدم والعزه والكرامه ليس لها خيار اخر واخر واخر ليه الدم واسترداد الأرض والعزه والكرامه>\n\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 396ms/step - loss: 0.4347 - val_loss: 0.3061\nEpoch 47/100\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332ms/step - loss: 0.4364\nEpoch 47: saving model to /kaggle/working/ASAR-v3/weights-improvement-47.model.keras\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 385ms/step - loss: 0.4363 - val_loss: 0.2847\nEpoch 48/100\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 331ms/step - loss: 0.4626\nEpoch 48: saving model to /kaggle/working/ASAR-v3/weights-improvement-48.model.keras\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 385ms/step - loss: 0.4627 - val_loss: 0.3184\nEpoch 49/100\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332ms/step - loss: 0.4478\nEpoch 49: saving model to /kaggle/working/ASAR-v3/weights-improvement-49.model.keras\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 385ms/step - loss: 0.4478 - val_loss: 0.2875\nEpoch 50/100\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332ms/step - loss: 0.4265\nEpoch 50: saving model to /kaggle/working/ASAR-v3/weights-improvement-50.model.keras\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 388ms/step - loss: 0.4265 - val_loss: 0.2779\nEpoch 51/100\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 333ms/step - loss: 0.4178\nEpoch 51: saving model to /kaggle/working/ASAR-v3/weights-improvement-51.model.keras\ntarget:     <دفع ضريبة الحريه الدم الدم واسترداد الأرض والعزه والكرامه ليس لها خيار اخر>\nprediction: <دفع ضريبة الحريه الدم والعزه والكرامه ليس لها خيار أخيار اخر والعزه والكرامه ليس لها خيار>\n\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m229s\u001b[0m 397ms/step - loss: 0.4178 - val_loss: 0.2740\nEpoch 52/100\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 333ms/step - loss: 0.4148\nEpoch 52: saving model to /kaggle/working/ASAR-v3/weights-improvement-52.model.keras\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 386ms/step - loss: 0.4148 - val_loss: 0.3036\nEpoch 53/100\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332ms/step - loss: 0.4288\nEpoch 53: saving model to /kaggle/working/ASAR-v3/weights-improvement-53.model.keras\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 386ms/step - loss: 0.4288 - val_loss: 0.2766\nEpoch 54/100\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332ms/step - loss: 0.4092\nEpoch 54: saving model to /kaggle/working/ASAR-v3/weights-improvement-54.model.keras\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 387ms/step - loss: 0.4092 - val_loss: 0.2708\nEpoch 55/100\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332ms/step - loss: 0.4032\nEpoch 55: saving model to /kaggle/working/ASAR-v3/weights-improvement-55.model.keras\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 386ms/step - loss: 0.4032 - val_loss: 0.2686\nEpoch 56/100\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332ms/step - loss: 0.4007\nEpoch 56: saving model to /kaggle/working/ASAR-v3/weights-improvement-56.model.keras\ntarget:     <دفع ضريبة الحريه الدم الدم واسترداد الأرض والعزه والكرامه ليس لها خيار اخر>\nprediction: <دفع ضريبة الحريه الدم واسترداد الأرض والعزه والكرامه ليس لها خيار اخر>\n\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m229s\u001b[0m 397ms/step - loss: 0.4007 - val_loss: 0.2662\nEpoch 57/100\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332ms/step - loss: 0.3985\nEpoch 57: saving model to /kaggle/working/ASAR-v3/weights-improvement-57.model.keras\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 385ms/step - loss: 0.3985 - val_loss: 0.2657\nEpoch 58/100\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332ms/step - loss: 0.3995\nEpoch 58: saving model to /kaggle/working/ASAR-v3/weights-improvement-58.model.keras\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 385ms/step - loss: 0.3995 - val_loss: 0.2666\nEpoch 59/100\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332ms/step - loss: 0.3960\nEpoch 59: saving model to /kaggle/working/ASAR-v3/weights-improvement-59.model.keras\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 385ms/step - loss: 0.3960 - val_loss: 0.2635\nEpoch 60/100\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332ms/step - loss: 0.3936\nEpoch 60: saving model to /kaggle/working/ASAR-v3/weights-improvement-60.model.keras\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 385ms/step - loss: 0.3936 - val_loss: 0.2629\nEpoch 61/100\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332ms/step - loss: 0.3931\nEpoch 61: saving model to /kaggle/working/ASAR-v3/weights-improvement-61.model.keras\ntarget:     <دفع ضريبة الحريه الدم الدم واسترداد الأرض والعزه والكرامه ليس لها خيار اخر>\nprediction: <دفع ضريبة الحريه الدم واسترداد الأرض والعزه والكرامه ليس لها خيار اخر>\n\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m229s\u001b[0m 397ms/step - loss: 0.3931 - val_loss: 0.2625\nEpoch 62/100\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332ms/step - loss: 0.3916\nEpoch 62: saving model to /kaggle/working/ASAR-v3/weights-improvement-62.model.keras\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 385ms/step - loss: 0.3916 - val_loss: 0.2624\nEpoch 63/100\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332ms/step - loss: 0.3904\nEpoch 63: saving model to /kaggle/working/ASAR-v3/weights-improvement-63.model.keras\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 386ms/step - loss: 0.3904 - val_loss: 0.2625\nEpoch 64/100\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332ms/step - loss: 0.3886\nEpoch 64: saving model to /kaggle/working/ASAR-v3/weights-improvement-64.model.keras\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 386ms/step - loss: 0.3886 - val_loss: 0.2621\nEpoch 65/100\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 331ms/step - loss: 0.3983\nEpoch 65: saving model to /kaggle/working/ASAR-v3/weights-improvement-65.model.keras\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 385ms/step - loss: 0.3983 - val_loss: 0.2666\nEpoch 66/100\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 331ms/step - loss: 0.3906\nEpoch 66: saving model to /kaggle/working/ASAR-v3/weights-improvement-66.model.keras\ntarget:     <دفع ضريبة الحريه الدم الدم واسترداد الأرض والعزه والكرامه ليس لها خيار اخر>\nprediction: <دفع ضريبة الحريه الدم واسترداد الأرض والعزه والكرامه ليس لها خيار اخر>\n\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 395ms/step - loss: 0.3906 - val_loss: 0.2602\nEpoch 67/100\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332ms/step - loss: 0.3793\nEpoch 67: saving model to /kaggle/working/ASAR-v3/weights-improvement-67.model.keras\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 385ms/step - loss: 0.3793 - val_loss: 0.2565\nEpoch 68/100\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332ms/step - loss: 0.3749\nEpoch 68: saving model to /kaggle/working/ASAR-v3/weights-improvement-68.model.keras\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 386ms/step - loss: 0.3749 - val_loss: 0.2577\nEpoch 69/100\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332ms/step - loss: 0.3728\nEpoch 69: saving model to /kaggle/working/ASAR-v3/weights-improvement-69.model.keras\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 386ms/step - loss: 0.3728 - val_loss: 0.2577\nEpoch 70/100\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332ms/step - loss: 0.3717\nEpoch 70: saving model to /kaggle/working/ASAR-v3/weights-improvement-70.model.keras\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 386ms/step - loss: 0.3717 - val_loss: 0.2549\nEpoch 71/100\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332ms/step - loss: 0.3736\nEpoch 71: saving model to /kaggle/working/ASAR-v3/weights-improvement-71.model.keras\ntarget:     <دفع ضريبة الحريه الدم الدم واسترداد الأرض والعزه والكرامه ليس لها خيار اخر>\nprediction: <دفع ضريبة الحريه الدم الدم واسترداد الأرض والعزه والكرامه ليس لها خيار اخر>\n\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 396ms/step - loss: 0.3736 - val_loss: 0.2586\nEpoch 72/100\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332ms/step - loss: 0.3760\nEpoch 72: saving model to /kaggle/working/ASAR-v3/weights-improvement-72.model.keras\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 386ms/step - loss: 0.3760 - val_loss: 0.2578\nEpoch 73/100\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332ms/step - loss: 0.3724\nEpoch 73: saving model to /kaggle/working/ASAR-v3/weights-improvement-73.model.keras\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 385ms/step - loss: 0.3724 - val_loss: 0.2566\nEpoch 74/100\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332ms/step - loss: 0.3695\nEpoch 74: saving model to /kaggle/working/ASAR-v3/weights-improvement-74.model.keras\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 385ms/step - loss: 0.3695 - val_loss: 0.2564\nEpoch 75/100\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332ms/step - loss: 0.3675\nEpoch 75: saving model to /kaggle/working/ASAR-v3/weights-improvement-75.model.keras\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 385ms/step - loss: 0.3675 - val_loss: 0.2559\nEpoch 76/100\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 331ms/step - loss: 0.3660\nEpoch 76: saving model to /kaggle/working/ASAR-v3/weights-improvement-76.model.keras\ntarget:     <دفع ضريبة الحريه الدم الدم واسترداد الأرض والعزه والكرامه ليس لها خيار اخر>\nprediction: <دفع ضريبة الحريه الدم الدم واسترداد الأرض والعزه والكرامه ليس لها خيار اخر>\n\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 395ms/step - loss: 0.3660 - val_loss: 0.2555\nEpoch 77/100\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332ms/step - loss: 0.3642\nEpoch 77: saving model to /kaggle/working/ASAR-v3/weights-improvement-77.model.keras\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 386ms/step - loss: 0.3642 - val_loss: 0.2548\nEpoch 78/100\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 331ms/step - loss: 0.3622\nEpoch 78: saving model to /kaggle/working/ASAR-v3/weights-improvement-78.model.keras\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 385ms/step - loss: 0.3622 - val_loss: 0.2544\nEpoch 79/100\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332ms/step - loss: 0.3602\nEpoch 79: saving model to /kaggle/working/ASAR-v3/weights-improvement-79.model.keras\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 386ms/step - loss: 0.3602 - val_loss: 0.2536\nEpoch 80/100\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332ms/step - loss: 0.3583\nEpoch 80: saving model to /kaggle/working/ASAR-v3/weights-improvement-80.model.keras\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 386ms/step - loss: 0.3583 - val_loss: 0.2524\nEpoch 81/100\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332ms/step - loss: 0.3553\nEpoch 81: saving model to /kaggle/working/ASAR-v3/weights-improvement-81.model.keras\ntarget:     <دفع ضريبة الحريه الدم الدم واسترداد الأرض والعزه والكرامه ليس لها خيار اخر>\nprediction: <دفع ضريبة الحريه الدم الدم واسترداد الأرض والعزه والكرامه ليس لها خيار اخر>\n\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 396ms/step - loss: 0.3553 - val_loss: 0.2510\nEpoch 82/100\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332ms/step - loss: 0.3524\nEpoch 82: saving model to /kaggle/working/ASAR-v3/weights-improvement-82.model.keras\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 385ms/step - loss: 0.3524 - val_loss: 0.2499\nEpoch 83/100\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332ms/step - loss: 0.3501\nEpoch 83: saving model to /kaggle/working/ASAR-v3/weights-improvement-83.model.keras\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 386ms/step - loss: 0.3501 - val_loss: 0.2501\nEpoch 84/100\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332ms/step - loss: 0.3482\nEpoch 84: saving model to /kaggle/working/ASAR-v3/weights-improvement-84.model.keras\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 386ms/step - loss: 0.3482 - val_loss: 0.2502\nEpoch 85/100\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 331ms/step - loss: 0.3460\nEpoch 85: saving model to /kaggle/working/ASAR-v3/weights-improvement-85.model.keras\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 385ms/step - loss: 0.3460 - val_loss: 0.2505\nEpoch 86/100\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 331ms/step - loss: 0.3436\nEpoch 86: saving model to /kaggle/working/ASAR-v3/weights-improvement-86.model.keras\ntarget:     <دفع ضريبة الحريه الدم الدم واسترداد الأرض والعزه والكرامه ليس لها خيار اخر>\nprediction: <دفع ضريبة الحريه الدم الدم واسترداد الأرض والعزه والكرامه ليس لها خيار اخر>\n\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 396ms/step - loss: 0.3436 - val_loss: 0.2503\nEpoch 87/100\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 331ms/step - loss: 0.3412\nEpoch 87: saving model to /kaggle/working/ASAR-v3/weights-improvement-87.model.keras\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 384ms/step - loss: 0.3411 - val_loss: 0.2503\nEpoch 88/100\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 331ms/step - loss: 0.3392\nEpoch 88: saving model to /kaggle/working/ASAR-v3/weights-improvement-88.model.keras\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 384ms/step - loss: 0.3392 - val_loss: 0.2493\nEpoch 89/100\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 331ms/step - loss: 0.3374\nEpoch 89: saving model to /kaggle/working/ASAR-v3/weights-improvement-89.model.keras\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 385ms/step - loss: 0.3374 - val_loss: 0.2494\nEpoch 90/100\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 331ms/step - loss: 0.3351\nEpoch 90: saving model to /kaggle/working/ASAR-v3/weights-improvement-90.model.keras\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 384ms/step - loss: 0.3351 - val_loss: 0.2482\nEpoch 91/100\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 331ms/step - loss: 0.3327\nEpoch 91: saving model to /kaggle/working/ASAR-v3/weights-improvement-91.model.keras\ntarget:     <دفع ضريبة الحريه الدم الدم واسترداد الأرض والعزه والكرامه ليس لها خيار اخر>\nprediction: <دفع ضريبة الحريه الدم واسترداد الأرض والعزه والكرامه ليس لها خيار الدم الدم واسترداد الأرض والعزه والكرامه>\n\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 395ms/step - loss: 0.3327 - val_loss: 0.2482\nEpoch 92/100\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 331ms/step - loss: 0.3302\nEpoch 92: saving model to /kaggle/working/ASAR-v3/weights-improvement-92.model.keras\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 385ms/step - loss: 0.3302 - val_loss: 0.2470\nEpoch 93/100\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 331ms/step - loss: 0.3278\nEpoch 93: saving model to /kaggle/working/ASAR-v3/weights-improvement-93.model.keras\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 385ms/step - loss: 0.3278 - val_loss: 0.2455\nEpoch 94/100\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 331ms/step - loss: 0.3256\nEpoch 94: saving model to /kaggle/working/ASAR-v3/weights-improvement-94.model.keras\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 385ms/step - loss: 0.3256 - val_loss: 0.2457\nEpoch 95/100\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 331ms/step - loss: 0.3233\nEpoch 95: saving model to /kaggle/working/ASAR-v3/weights-improvement-95.model.keras\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 385ms/step - loss: 0.3233 - val_loss: 0.2459\nEpoch 96/100\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 331ms/step - loss: 0.3210\nEpoch 96: saving model to /kaggle/working/ASAR-v3/weights-improvement-96.model.keras\ntarget:     <دفع ضريبة الحريه الدم الدم واسترداد الأرض والعزه والكرامه ليس لها خيار اخر>\nprediction: <دفع ضريبة الحريه الدم واسترداد الأرض والعزه والكرامه ليس لها خيار اخر>\n\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 395ms/step - loss: 0.3210 - val_loss: 0.2455\nEpoch 97/100\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 331ms/step - loss: 0.3190\nEpoch 97: saving model to /kaggle/working/ASAR-v3/weights-improvement-97.model.keras\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 385ms/step - loss: 0.3190 - val_loss: 0.2444\nEpoch 98/100\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 331ms/step - loss: 0.3173\nEpoch 98: saving model to /kaggle/working/ASAR-v3/weights-improvement-98.model.keras\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 384ms/step - loss: 0.3173 - val_loss: 0.2440\nEpoch 99/100\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 331ms/step - loss: 0.3163\nEpoch 99: saving model to /kaggle/working/ASAR-v3/weights-improvement-99.model.keras\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 385ms/step - loss: 0.3163 - val_loss: 0.2442\nEpoch 100/100\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332ms/step - loss: 0.3163\nEpoch 100: saving model to /kaggle/working/ASAR-v3/weights-improvement-100.model.keras\n\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 404ms/step - loss: 0.3163 - val_loss: 0.2447\n","output_type":"stream"},{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"'\\nIn practice, you should train for around 100 epochs or more.\\n\\nSome of the predicted text at or around epoch 35 may look as follows:\\n\\ntarget:     <as they sat in the car, frazier asked oswald where his lunch was>\\nprediction: <as they sat in the car frazier his lunch ware mis lunch was>\\n\\ntarget:     <under the entry for may one, nineteen sixty,>\\nprediction: <under the introus for may monee, nin the sixty,>\\n\\n'"},"metadata":{}}]},{"cell_type":"markdown","source":"## Testing","metadata":{}},{"cell_type":"code","source":"!pip install jiwer","metadata":{"execution":{"iopub.status.busy":"2024-07-01T11:28:13.272564Z","iopub.execute_input":"2024-07-01T11:28:13.273043Z","iopub.status.idle":"2024-07-01T11:28:27.866975Z","shell.execute_reply.started":"2024-07-01T11:28:13.273012Z","shell.execute_reply":"2024-07-01T11:28:27.865755Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"Collecting jiwer\n  Downloading jiwer-3.0.4-py3-none-any.whl.metadata (2.6 kB)\nRequirement already satisfied: click<9.0.0,>=8.1.3 in /opt/conda/lib/python3.10/site-packages (from jiwer) (8.1.7)\nCollecting rapidfuzz<4,>=3 (from jiwer)\n  Downloading rapidfuzz-3.9.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\nDownloading jiwer-3.0.4-py3-none-any.whl (21 kB)\nDownloading rapidfuzz-3.9.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m61.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: rapidfuzz, jiwer\nSuccessfully installed jiwer-3.0.4 rapidfuzz-3.9.3\n","output_type":"stream"}]},{"cell_type":"code","source":"# import os\n# model=None\n\n# # Edit epoch number to start from saved epoch\n# model = keras.models.load_model(\n#     \"my_model_v3.keras\",\n#     compile=False,\n#     custom_objects={\"Transformer\": Transformer}\n# )\n\n# model.summary()","metadata":{"execution":{"iopub.status.busy":"2024-07-01T11:29:33.149851Z","iopub.execute_input":"2024-07-01T11:29:33.150234Z","iopub.status.idle":"2024-07-01T11:29:36.031388Z","shell.execute_reply.started":"2024-07-01T11:29:33.150201Z","shell.execute_reply":"2024-07-01T11:29:36.030501Z"},"trusted":true},"execution_count":25,"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"transformer_5\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"transformer_5\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ speech_feature_embedding_6      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)      │     \u001b[38;5;34m1,164,400\u001b[0m │\n│ (\u001b[38;5;33mSpeechFeatureEmbedding\u001b[0m)        │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ token_embedding_6               │ ?                      │        \u001b[38;5;34m50,400\u001b[0m │\n│ (\u001b[38;5;33mTokenEmbedding\u001b[0m)                │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ sequential_40 (\u001b[38;5;33mSequential\u001b[0m)      │ ?                      │     \u001b[38;5;34m3,095,600\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ transformer_decoder_6           │ ?                      │       \u001b[38;5;34m804,600\u001b[0m │\n│ (\u001b[38;5;33mTransformerDecoder\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_76 (\u001b[38;5;33mDense\u001b[0m)                │ ?                      │        \u001b[38;5;34m10,452\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ speech_feature_embedding_6      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,164,400</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpeechFeatureEmbedding</span>)        │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ token_embedding_6               │ ?                      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">50,400</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TokenEmbedding</span>)                │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ sequential_40 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)      │ ?                      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,095,600</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ transformer_decoder_6           │ ?                      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">804,600</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecoder</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_76 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ ?                      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,452</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,961,052\u001b[0m (15.11 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,961,052</span> (15.11 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,961,052\u001b[0m (15.11 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,961,052</span> (15.11 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}]},{"cell_type":"code","source":"# val_data = data[split+5:]\n# test_ds = create_tf_dataset(val_data, bs=4)","metadata":{"execution":{"iopub.status.busy":"2024-07-01T11:29:42.046331Z","iopub.execute_input":"2024-07-01T11:29:42.047191Z","iopub.status.idle":"2024-07-01T11:29:42.384276Z","shell.execute_reply.started":"2024-07-01T11:29:42.047160Z","shell.execute_reply":"2024-07-01T11:29:42.383456Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"# from jiwer import wer,cer\n\n\n# cnt=10\n# targets=[]\n# predictions=[]\n# for i in ds:\n#     cnt-=1\n#     if cnt==0:\n#         break\n#     source=i['source']\n#     target=i['target']\n#     target_start_token_idx=2\n#     target_end_token_idx=3\n#     preds = model.generate(source, target_start_token_idx)\n#     preds = preds.numpy()\n    \n#     target_text = \"\".join([idx_to_char[_] for _ in target[0, :]])\n#     prediction = \"\"\n#     for idx in preds[0, :]:\n#         prediction += idx_to_char[idx]\n#         if idx == target_end_token_idx:\n#             break\n#     print(f\"target{cnt}:     {target_text.replace('-','')}\")\n#     print(f\"prediction{cnt}: {prediction}\\n\")\n#     targets.append(target_text.replace('-',''))\n#     predictions.append(prediction)\n# wer_score = wer(targets, predictions)*100\n# cer_score = cer(targets, predictions)*100\n# print(f\"Word Error Rate: {wer_score:.4f}\")\n# print(f\"Char Error Rate: {cer_score:.4f}\")\n\n    \n# print(\"On test:\")\n\n# cnt=10\n\n# targets=[]\n# predictions=[]\n# for i in test_ds:\n#     cnt-=1\n#     if cnt==0:\n#         break\n#     source=i['source']\n#     target=i['target']\n#     target_start_token_idx=2\n#     target_end_token_idx=3\n#     preds = model.generate(source, target_start_token_idx)\n#     preds = preds.numpy()\n    \n#     target_text = \"\".join([idx_to_char[_] for _ in target[0, :]])\n#     prediction = \"\"\n#     for idx in preds[0, :]:\n#         prediction += idx_to_char[idx]\n#         if idx == target_end_token_idx:\n#             break\n#     print(f\"target{cnt}:     {target_text.replace('-','')}\")\n#     print(f\"prediction{cnt}: {prediction}\\n\")\n#     targets.append(target_text.replace('-',''))\n#     predictions.append(prediction)\n# wer_score = wer(targets, predictions)*100\n# cer_score = cer(targets, predictions)*100\n# print(f\"Word Error Rate: {wer_score:.4f}\")\n# print(f\"Char Error Rate: {cer_score:.4f}\")","metadata":{"execution":{"iopub.status.busy":"2024-07-01T11:30:26.600587Z","iopub.execute_input":"2024-07-01T11:30:26.600971Z","iopub.status.idle":"2024-07-01T11:32:19.731561Z","shell.execute_reply.started":"2024-07-01T11:30:26.600939Z","shell.execute_reply":"2024-07-01T11:32:19.730603Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"target9:     <سنوات العمر هو متاخد يعني ب بيتعالجوا كان كان الأول سو سينسيتيف>\nprediction9: <سنوات العمر هو متاخد يعني بيتعالجبي كان كان الأول سينس تاخد يعني بيتاعا البيها بيتد>\n\ntarget8:     <الشرق للغرب الفرق إيه يا فندم الفرق إيه>\nprediction8: <الشرق للفرق إيه في فندم الفرق إيه>\n\ntarget7:     <بسبب اللعبه برضو سابهم ليه اللعبه هي أصلا اللعبه ديت>\nprediction7: <بسبب اللعبه دي أصلا اللعبه يا أصلا اللعبه دي أصلا باللعبه دي>\n\ntarget6:     <كما أشار سيادة اللواء إن هو تقدم الصفوف و هو كان أول واحد يستشهد يعني في هذه المعركه>\nprediction6: <كما أشار سيادة اللواء إن هو تقدم الصفوف و هو كان أول واحد يستشهر سيادة اللواء إن هو كان أول واحد يستشهر سيادة اللواء إن هو>\n\ntarget5:     <أسيب بنتي في سن صغير و أنزل أشتغل و هنا أنا بوجه التحيه فعلا لكل أم>\nprediction5: <أسيب بنتي في سين صغير و أنا أنا بوجه اتحيه فعلا لكل أم من السن صغير و أنا أنا بوجه إحن>\n\ntarget4:     <المنطقه فيها فهد>\nprediction4: <المنصيتك فيها فهم>\n\ntarget3:     <في داخلي سؤال يعني أستحي أن أسأله>\nprediction3: <في داخلي سؤال يعني أستحي أن أسأله>\n\ntarget2:     <اشتغلت مع يحيى الفخراني أيوه مظبوط في المسلسل مكنتش لسه إيمي نطرت>\nprediction2: <اشتغلت مع يحيى الفخراني هي الفخراني هي الفخراني هي الفخراني هي>\n\ntarget1:     <اتفضل شكرا معالي الرئيس>\nprediction1: <اتفضل تم على الرئيس>\n\nWord Error Rate: 65.5556\nChar Error Rate: 43.4783\nOn test:\ntarget9:     <وتدير الفرص الفتره اللي جايه يمكن مصر في شهر حداشر اللي جاي في الكوب>\nprediction9: <وتديل الفور السفات لجال كتير في الفور السفات لجال جايه>\n\ntarget8:     <كان العاملين في التليفزيون بينزلوا يتفرجوا عشان يتصوروا جمب التمبوكه إم>\nprediction8: <إن اللي عاملين في اتصور جم بنزلوا يتصوروا جم بنزلوا يتصوروا جم بنزله العمل إيه في اتصور>\n\ntarget7:     <إم أرض الخوف بقى في في تراكات كتير جدا محتاجه تأمل إم ومحتاج أفكر>\nprediction7: <إم أرض الخب في أرض الخبر جدا محتاج أوي و التلك كتيره جدا أوض>\n\ntarget6:     <أنا بدفع أتعاب محامي عند رفع الدعوى هو بيستفيد منها أنا مبستفيدش منها تمام>\nprediction6: <إحنا بتلاقيت من أنا بت و بيستشي من أنا بتشوفيد ده أنا بيستشار مات>\n\ntarget5:     <من مستويات الفايده وما يسببه من انكماش يؤثر على مستويات البورصه>\nprediction5: <المستويات الفايده وميه وسببيهموا يا سبببهموا الصب و ما يا سبيطه الورصه>\n\ntarget4:     <معهوش اللضا خالص بيشيل طوب>\nprediction4: <معوش الموضوع شير اللي تاني>\n\ntarget3:     <الأغاني إللي بيعملها ده حقيقي إختلفنا إتفقنا هو نمبر وان هو الأول في الغني>\nprediction3: <غني اللي بيعملها التفق نعمبر من معملها يخلي على الغذنا يلل بيعملها يخلعلال نفعلا نعمر>\n\ntarget2:     <يعني أنا حد ينزلي فيديوهات على التيك توك والفيديوهات نجحت>\nprediction2: <يعني هنا حد النظري بيبقي على الإنتوا على الإنتا>\n\ntarget1:     <يا بنتي طيب ما هو في غيرك هيقول أستاذ مش عاجبني حصل مشكله حصل أنا دايما البؤ أنا دايما الصوت اللي طالع فطبعا الشخص اللي بيعمل كده>\nprediction1: <يعني لفنا دايما ننرج أنا دايما بين للطب عمل كده أنا دايما ننري بين للقي السواب ده بري البيع من التسوب مش عارف باللي هفقوله إستاذه و شق اللي فطب دايما ن>\n\nWord Error Rate: 102.5000\nChar Error Rate: 64.3411\n","output_type":"stream"}]}]}